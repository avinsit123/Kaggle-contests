{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk import FreqDist\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn import feature_extraction\nimport os\nprint(os.listdir(\"../input\"))\nimport keras\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/train.tsv\",sep=\"\\t\")\ntest=pd.read_csv(\"../input/test.tsv\",sep=\"\\t\")\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d12a0c41a9317e80fdfb7c7b27ed3a9cb8525afa"},"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nfrom nltk import FreqDist\nfrom nltk.stem import SnowballStemmer,WordNetLemmatizer\nstemmer=SnowballStemmer('english')\nlemma=WordNetLemmatizer()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81139867af3b124e5e008266c2f2e69989b7fd3a"},"cell_type":"code","source":"def lemmize(column):\n    leem=[]\n    for sentence in column:\n        lassos= [lemma.lemmatize(word) for word in word_tokenize(sentence)]\n        lassos=' '.join(lassos)\n        leem.append(lassos)\n    return leem\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"522d54c84f2a8f502cf802e92632514949e0b71e"},"cell_type":"code","source":"train['clean_review']=lemmize(train[\"Phrase\"])\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2414ecd171245799b7f15065a59cbde036b381db"},"cell_type":"code","source":"X=train.clean_review.values\ny=train.Sentiment.values\ny=keras.utils.to_categorical(y,num_classes=5)\nfrom sklearn.model_selection import train_test_split\n(X_train,X_val,y_train,y_val)=train_test_split(X,y,test_size=0.3,random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7c6a6d104d48ad35ba1fba12e07f7dae6dce3ca"},"cell_type":"code","source":"def distinct_words(X):\n    totsent=\"\"\n    for sentence in X:\n        totsent+=sentence\n    alword=word_tokenize(totsent)\n    return len(FreqDist(alword)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecd233b6cb2953f834d735d04afa9338b8d3298f"},"cell_type":"code","source":"def MAX_LENGTH(X):\n    for sent in X:\n      r_len=[]\n      gre=word_tokenize(sent)\n      r_len.append(len(gre))\n    max_sent=(np.max(r_len))\n    return max_sent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d09c9cf3a6e35ce7fc79a7a73e884af0ae4d0d77"},"cell_type":"code","source":"dXt=distinct_words(X_train)\ndXval=distinct_words(X_val)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5640ab352dade5a1f79539e708f8da30b1f3d86"},"cell_type":"code","source":"dXt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbe9e497b2116526aa67f895007a30e69ede514c","scrolled":true},"cell_type":"code","source":"tokenize=Tokenizer(num_words=distinct_words(X_train))\ntokenize.fit_on_texts(list(X_train))\nX_train=tokenize.texts_to_sequences(X_train)\nX_val=tokenize.texts_to_sequences(X_val)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a857feaa39f0d1b98dde460eb9d82d51d44d294"},"cell_type":"code","source":"from keras.preprocessing import sequence,text\nX_train=sequence.pad_sequences(X_train,maxlen=53)\nX_val=sequence.pad_sequences(X_val,maxlen=53)\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9aba9d9079d10062aeb68e1ed18ae40dbc29cc6"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM,Embedding,Dense\nfrom keras.optimizers import Adam\nmodel1=Sequential()\nmodel1.add(Embedding(dXt,100,mask_zero=True))\nmodel1.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\nmodel1.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\nmodel1.add(Dense(5,activation='softmax'))\nmodel1.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23af0171c73cbf740070712761ad908e7e6e1152"},"cell_type":"code","source":"history1=model1.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=5, batch_size=128, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"954d269c7af4037493bad95e9a01555969355545"},"cell_type":"code","source":"import matplotlib.pyplot as plt \ndef plot(history):\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"923b2ecd5247ab2b5e48ce6b01f1f8658e02793d"},"cell_type":"code","source":"X_test=pd.read_csv(\"../input/test.tsv\",sep='\\t')\nX_test['clean_review']=lemmize(X_test[\"Phrase\"])\nX_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d76233a49123de32cb3c6737d9c2d1dde843b9c0"},"cell_type":"code","source":"X_t=X_test['clean_review']\ndt=distinct_words(X_t)\nprint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7be3aca445ff38d6c37fa4dcc46286e397ca12a3"},"cell_type":"code","source":"X_t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c56ba1f9d0b8193393f31a1df3c025aa243b77a"},"cell_type":"code","source":"X_t=tokenize.texts_to_sequences(X_t)\nX_t=sequence.pad_sequences(X_t,maxlen=53)\nX_t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"516ad5e7cef3a79c8acdd9673b88465ab04e0a74"},"cell_type":"code","source":"prediction=model1.predict_classes(X_t,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a76ea98fe99834f34d9d42816caed1c321c299f"},"cell_type":"code","source":"sub=pd.read_csv('../input/sampleSubmission.csv')\nsub.Sentiment=prediction\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"203c57656951e56545950603a34e42d29b975ff9"},"cell_type":"code","source":"sub.to_csv('lu.csv',index=False)\nsub.head(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}